標本分散<-numeric(length = 10000)
不偏分散<-numeric(length = 10000)

for(i in 1:10000){
  標本<-rnorm(n=10,mean=50,sd=10)
  標本分散[i]<-mean((標本-mean(標本))^2)
  不偏分散[i]<-var(標本)
}



標本平均<-numeric(length = 10000)
標本中央値<-numeric(length = 10000)

for(i in 1:10000) {
  標本<-rnorm(n=10,mean=50,sd=10)
  標本平均[i]<-mean(標本)
  標本中央値[i]<-median(標本)
}

#第４章
#練習問題P107
(1)
標本平均<-numeric(length = 5000)

for(i in 1:5000){
  標本<-rnorm(n=20,mean=50,sd=10)
  標本平均[i]<-mean(標本)
}

#(2)
curve(dnorm(x,mean=0,sd=1/25), -3,3)
curve(dnorm(x,mean=0,sd=1/16), -3,3, add=TRUE)
curve(dnorm(x,mean=0,sd=1/9), -3,3, add=TRUE)
curve(dnorm(x,mean=0,sd=1/4), -3,3, add=TRUE)
curve(dnorm(x,mean=0,sd=1/1), -3,3, add=TRUE)

#第５章
#練習問題P139
#(1)
t.test(標本, mu=170)　#t.test;t検定を母平均μ＝170の帰無仮説で実施
#(2)
cor.test(時間,得点) #cor.test;無相関検定を行う。デフォルトではピアソンの積率無相関検定
#(3)
cor.test(時間,得点,method='spearman')
cor.test(時間,得点,method='kenddall')
#(4)
chisq.test(クロス集計,correct = FALSE) #chisq.test;カイ二乗検定を行う
WAYO<-c('Y','W','W','Y','W','Y','Y','W','Y','Y','W','Y','W','Y','W','W','Y','Y','W','W')
AMKR<-C('A','K','A','A','K','K','K','K','A','A','A','A','K','K','A','K','K','A','K','K')
クロス集計<-table(WAYO,AMKR)
クロス集計
#     AMKR
#WAYO A K
   #W 3 7
   #Y 6 4
#chisq.testよりX(カイ二乗は1.8182)
curve(dchisq(x,1),0,10) #dchisqはカイ二乗分布の確率密度関数を描く
abline(v=qchisq(0.05,1,lower.tail = FALSE)) #qchisqは棄却域を出力
abline(v=1.8182,lty=2(3))
#(5-1)
国語<-c(60,40,30,70,55)
社会<-c(80,25,35,70,50)
cor.test(国語,社会)
curve(dt(x,3),-5,5) #dt; t分布の確率密度関数を描く
abline(v=qt(0.025,3)) #qt; t分布の棄却域を出力
abline(v=qt(0.975,3))
abline(v=2.6952,lty=3)
#棄却できない。相関関係は０である。

#(5-2)
国語２<-rep(国語,2)
社会２<-rep(社会,2)
cor.test(国語２,社会２)
curve(dt(x,6),-5,5) #dt; t分布の確率密度関数を描く
abline(v=qt(0.025,6)) #qt; t分布の棄却域を出力
abline(v=qt(0.975,6))
abline(v=4.4013,lty=4)
#棄却域に入る。相関関係あり。


第６章
#練習問題P158
#(6-1)
統計<-c('好き','好き','好き','好き','嫌い','嫌い','嫌い','嫌い','嫌い','嫌い','好き','好き','好き','嫌い','好き','嫌い','嫌い','嫌い','嫌い','嫌い')
統計テスト１<-c(6,10,6,10,5,3,5,9,3,3,11,6,11,9,7,5,8,7,7,9)
table(統計テスト１,統計)
統計テスト嫌い<-c(3,3,3,5,5,5,7,7,8,9,9,9)
統計テスト好き<-c(6,6,6,7,10,10,11,11)
var.test(統計テスト嫌い,統計テスト好き)
#p=0.978>0.05; 帰無仮説分散は等質であるを採択
t.test(統計テスト嫌い,統計テスト好き,var.equal = TRUE)
#p=0.048<0.05; 帰無仮説ふたつの群の平均は等しいを棄却。ふたつの群の平均には有意差がある

#(6-2)
心理学テスト<-c(13,14,7,12,10,6,8,15,4,14,9,6,10,12,5,12,8,8,12,15)
性別<-c('男','男','男','男','男','男','男','男','男','男','女','女','女','女','女','女','女','女','女','女')
table(心理学テスト,性別)
心理学テスト男<-c(4,6,7,8,10,12,13,14,14,15)
心理学テスト女<-c(5,6,8,8,9,10,12,12,12,15)
var.test(心理学テスト男,心理学テスト女)
#p=0.51>0.05; 帰無仮説分散は等質であるを採択
t.test(心理学テスト男,心理学テスト女,var.equal = TRUE)
#p=0.7058>0.05; 帰無仮説ふたつの群の平均は等しいを採択。ふたつの群の平均には有意差はない

#(6-3)
参加前<-c(61,50,41,55,51,48,46,55,65,70)
参加後<-c(59,48,33,54,47,52,38,50,64,63)
var.test(参加前,参加後)
#p=0.74>0.05; 帰無仮説分散は等質であるを採択
t.test(参加前,参加後,var.equal = TRUE)
#p=0.4344>0.05; 帰無仮説ふたつの群の平均は等しいを棄却。ふたつの群の平均には有意差がある
t.test(参加前,参加後,paired = TRUE)
#p=0.0192<0.05; 帰無仮説ふたつの群の平均は等しいを採択。ふたつの群の平均には有意差はない


#7章
#7-1
#F分布のグラフと棄却域およびq値の描き方。F値は４群すべての有意差7.1111
#q値は多重比較（Tukey）A群とD群とかのふたつの群間の有意差。例：A群とD群
#ｑ値は6.3956(TukeyHSD(aov(統計テスト２-指導法２))だとq-valueは出力されない)
curve(df(x,3,16),0,8)
abline(v=qtukey(0.95,4,16))#qtukeyで棄却域を計算
abline(v=6.3956, lty=2) #AとDの比較のq値6.3956; q<-abs(mean(A)-mean(D)/sqrt(郡内平均平方/nrow(全データ)))

#7-2
#F分布
curve(df(x,2,12),0,15) #df;Fｂ分布を描く
#棄却域
abline(v=qf(0.05,2,12,lower.tail = FALSE))#qf; F分布で下側確率の限界値を求める
#F値、summary(aov(好意度~科目+人))
abline(v=14.69,lty=2)

#7章練習問題
#(1)
得点<-c(75,61,68,58,66,55,65,63,62,60,66,63,55,53,59,63,65,60,78,52,59,66,73,64,52,59,44,67,47,53,58,49)
学部<-c(rep('法学部',8),rep('文学部',8),rep('理学部',8),rep('工学部',8))
全学部<-data.frame(学部,得点) #data.frameで見やすくなる。さらに文字列はfactor型になる
summary(aov(全学部$得点~全学部$学部)) #F Value=4.51, P=0.01
curve(df(x,3,28),0,5)
abline(v=qtukey(0.05,3,28,lower.tail = FALSE)) #qtukey; F分布で多重比較でのqの限界値を求める
abline(v=4.51,lty=2)
#有意差あり
TukeyHSD(aov(得点~学部))
#               diff       lwr       upr     p adj
#文学部-工学部  6.50 -2.634092 15.634092 0.2337032
#法学部-工学部 10.25  1.115908 19.384092 0.0233773
#理学部-工学部 11.00  1.865908 20.134092 0.0136621
#法学部-文学部  3.75 -5.384092 12.884092 0.6799312
#理学部-文学部  4.50 -4.634092 13.634092 0.5430095
#理学部-法学部  0.75 -8.384092  9.884092 0.9959313
#法学部-工学部,理学部-工学部の学部間で有意差あり

#(2)
点<-c(51,66,70,75,73,62,55,47,54,55,39,60,62,56,55,37,47,60,62,53,50)
学生<-rep(c('森本','田中','稲葉','瀬木','高橋','工藤','金子'),3)
方法<-rep(c('講義','問題','実習'),7)
summary(aov(点~方法+学生))
TukeyHSD(aov(点~方法+学生))


#第１５章 回帰分析
#データの作り方
set.seed(1234)
切片<-102.385888
父係数<-0.316514
母係数<-0.021370
父<-rnorm(n=19,mean=166.84211,sd=5.90916)
母<-rnorm
母<-rnorm(n=19,mean=155.94737,sd=4.63649)
残差<-rnorm(n=19,mean=0,sd=2.15664)
娘<-切片+父係数*父+母係数*母+残差
重回帰データ<-cbind(娘,父,母)
#重回帰データに両親の身長合計列を加えたい場合
両親合計<-父+母
重回帰データ２<-cbind(重回帰データ,両親合計)

plot(両親合計,娘)　# 両親合計が前にくること注意。逆にするとエラーは出ないがablineが引かれない・・・
abline(lm(娘~両親合計)) # lm(娘が前に来ること注意) lm:回帰結果を出力


#第１６章 因子分析（文系と理系という因子は有意か？）
#データの作り方
set.seed(9999)
n<-200
因子負荷行列<-matrix(c(0.09884,0.17545,0.52720,0.73462,0.45620,0.72141,0.47258,0.17901,0.07984,0.37204), nrow = 5)
独自性<-diag(sqrt(c(0.530201,0.254119,0.309986,0.546036,0.346539)))
因子得点<-matrix(rnorm(2*n),nrow = 2)
独自因子<-matrix(rnorm(5*n),nrow = 5)
五教科<-round(t(因子負荷行列%*%因子得点+独自性%*%独自因子)*10+50) # %*%は内積
colnames(五教科)<-c('国語','社会','数学','理科','英語')

#因子分析結果表作り方 P304
五教科因子分析<-factanal(五教科,factors = 2)
print(五教科因子分析,cutoff=0)
共通性<-1-五教科因子分析$uniquenesses


#第１７章（全然わからないのでスキップ）
#相関係数行列データの作り方
協調性<-read.moments(diag=FALSE,names=as.character(paste('y',1:12,sep='')))
1.000
.160 1.000
.302 .341 1.000
.461 .400 .372 1.000
.299 .404 .552 .302 1.000
.152 .320 .476 .225 .708 1.000
.134 .403 .467 .256 .623 .324 1.000
.182 .374 .572 .255 .776 .769 .724 1.000
.251 .285 .316 .164 .361 .295 .260 .284 1.000
.372 .100 .408 .236 .294 .206 .071 .142 .295 1.000
.157 .291 .393 .229 .472 .351 .204 .320 .290 .468 1.000
.206 -.014 .369 .224 .342 .202 .152 .189 .418 .351 .385 1.000

#測定方程式と構造方程式
model.協調性<-specify.model()
母親価値->y1, b11, NA
母親価値->y2, b21, NA
母親価値->y3, b31, NA
母親価値->y4, b41, NA
相互作用経験 -> y5, NA, 1
相互作用経験 -> y6, b62, 1
相互作用経験 -> y7, b72, 1
相互作用経験 -> y8, b82, 1
協調性 -> y9, NA, 1
協調性 -> y10, b103, NA
協調性 -> y11, b113, NA
協調性 -> y12, b123, NA
母親価値 -> 相互作用経験, g21, NA
母親価値 -> 協調性, g31, NA
y1 <-> y1, e1, NA
y2 <-> y2, e2, NA
y3 <-> y3, e3, NA
y4 <-> y4, e4, NA
y5 <-> y5, e5, NA
y6 <-> y6, e6, NA
y7 <-> y7, e7, NA
y8 <-> y8, e8, NA
y9 <-> y9, e9, NA
y10 <-> y10, e10, NA
y11 <-> y11, e11, NA
y12 <-> y12, e12, NA
母親価値 <-> 母親価値, NA, 1
相互作用経験 <-> 相互作用経験, delta2, NA
協調性 <-> 協調性, delta3, NA



#第１８章
#離散的確率分布にもとづく乱数を発生させてそれぞれを区分けする方法

#例：確率２０％で１，６０％で２、２０％で３をとるような確率分布に従う乱数発生方法
カテゴリ化前<-runif(n=10) #0~1までの乱数を１０個生成
[1] 0.46444123 0.86692410 0.38434020 0.06797511 0.64689684 0.85275882 0.37561439
[8] 0.21807600 0.16501694 0.75158513
カテゴリ化後<-cut(カテゴリ化前,c(0,0.2,0.8,1))
[1] (0.2,0.8] (0.8,1]   (0.2,0.8] (0,0.2]   (0.2,0.8] (0.8,1]   (0.2,0.8] (0.2,0.8]
[9] (0,0.2]   (0.2,0.8]
Levels: (0,0.2] (0.2,0.8] (0.8,1]
levels(カテゴリ化)<-1:3
カテゴリ化後
[1] 2 3 2 1 2 3 2 2 1 2
Levels: 1 2 3


#例：任意の母相関係数をもつ複数の変数データを発生させる方法
母相関<-0.6
変数x<-runif(n=100)
誤差e1<-runif(n=100)
誤差e2<-runif(n=100)
変数y1<-sqrt(母相関)*変数x+sqrt(1-母相関)*誤差e1
変数y2<-sqrt(母相関)*変数x+sqrt(1-母相関)*誤差e2
#これで変数y1と変数y2が相関係数が約0.6の乱数データになる。
> cor(変数y1,変数y2)
[1] 0.6216423
#３つめの変数y3を作りたい時は、誤差e3を作成して変数y3<-sqrt(母相関)*変数x+sqrt(1-母相関)*誤差e3とやればよい


#例：任意の相関行列をもつ多変量データ（上記の場合はすべての変数間の相関係数が同じ。以下は任意の母相関係数行列をもつ多変量データ発生方法）
サンプルサイズ<-10000
変数の数<-4
独立乱数<-matrix(rnorm(n=サンプルサイズ*変数の数),nrow=サンプルサイズ)
相関係数行列<-matrix(c(1.0,0.5,0.4,0.3,0.5,1.0,0.5,0.4,0.4,0.5,1.0,0.5,0.3,0.4,0.5,1.0),nrow=変数の数)
上三角行列<-chol(相関係数行列) # chol;コレスキー分解
観測値<-独立乱数%*%上三角行列
cor(観測値)
[,1]      [,2]      [,3]      [,4]
[1,] 1.0000000 0.5024343 0.3887438 0.2988854
[2,] 0.5024343 1.0000000 0.5083590 0.4001013
[3,] 0.3887438 0.5083590 1.0000000 0.5099222
[4,] 0.2988854 0.4001013 0.5099222 1.0000000
#相関係数行列と似た数字になる


#例：多変量正規分布に従うデータ
サンプルサイズ<-10000
変数の数<-4
独立乱数<-matrix(rnorm(n=サンプルサイズ*変数の数),nrow=サンプルサイズ)
平均行列<-matrix(rep(c(1,2,3,4),サンプルサイズ),nrow=サンプルサイズ,byrow=TRUE)
相関係数行列<-matrix(c(1.0,0.5,0.4,0.3,0.5,1.0,0.5,0.4,0.4,0.5,1.0,0.5,0.3,0.4,0.5,1.0),nrow=変数の数)
上三角行列<-chol(相関係数行列) # chol;コレスキー分解
観測値<-独立乱数%*%上三角行列+平均行列
cov(観測値) #cov()分散値もとめる
[,1]      [,2]      [,3]      [,4]
[1,] 1.0018690 0.5013000 0.3892618 0.2973926
[2,] 0.5013000 0.9936327 0.5069397 0.3964632
[3,] 0.3892618 0.5069397 1.0007965 0.5071037
[4,] 0.2973926 0.3964632 0.5071037 0.9881889

#回帰分析モデル
サンプルサイズ=100
切片<-10
偏回帰係数１<-3
偏回帰係数２<-0.5
x1<-rnorm(n=サンプルサイズ)
x2<-runif(n=サンプルサイズ,min = 0,max = 100) #runif();0~100までの一様分布の乱数を作成
e<-rnorm(n=サンプルサイズ,sd=10) 
y<-切片+偏回帰係数１*x1+偏回帰係数２*x2+e # y=a+b1x1+b2x2+eが重回帰分布モデル。aが切片、b1,b2が偏回帰係数、eが残差
>y
[1] 25.424422 49.763071 62.926383 20.223104 21.831485 27.728211 60.515629 54.647131 24.948716 16.249808
[11] 51.246456 76.016626 54.223722 32.813809  5.085218 17.398819 21.933901 -9.365007 67.668132 68.648312
[21] 65.060318 40.674811 28.798657 41.129191 25.716651 37.514863 16.495045 17.475709 10.287922  7.535384
[31] 23.070267 31.505289 41.690449 32.887946 18.608730 43.268304  9.283326 35.076004 36.039687 -6.726133
[41] 28.580749  7.146992 38.089437 55.646275 27.586455 55.405437  3.243969 50.108571 53.019319 22.632923
[51] 35.824926  9.866365 74.442506 30.212569 24.118176 68.515456 51.591751 52.335159 20.392674 41.716775
[61]  7.336905 47.420901 33.202828 34.382265 59.422093 22.355871 61.676405 39.095773 12.174984 42.780228
[71] -3.896902 51.675079 21.318355 44.311874 17.203246 20.724358 58.609138 23.238851 27.139930 21.079622
[81] 30.602040 11.278671 45.509926 22.544549 19.762969 21.266389 40.442355  5.846705 53.367546 14.194565
[91] 73.435906 22.468550 11.519106 40.988639 43.249632 41.633454 37.999270 40.063037 57.906873 34.298141

lm(y~x1+x2)
Coefficients:
  (Intercept)           x1           x2  
7.2119       2.5308       0.5525  
#偏回帰係数が設定した3と0.5に近くなってる


#因子分析モデル
サンプルサイズ<-1000
a11<-0.6
a12<-0.2
a21<-0.6
a22<-0.2
a31<-0.2
a32<-0.6
a41<-0.2
a42<-0.6
a51<-0.4
a52<-0.4
f1<-rnorm(n=サンプルサイズ)
f2<-rnorm(n=サンプルサイズ)
u1<-rnorm(n=サンプルサイズ,sd=sqrt(0.6))
u2<-rnorm(n=サンプルサイズ,sd=sqrt(0.6))
u3<-rnorm(n=サンプルサイズ,sd=sqrt(0.6))
u4<-rnorm(n=サンプルサイズ,sd=sqrt(0.6))
u5<-rnorm(n=サンプルサイズ,sd=sqrt(0.68))
x1<-a11*f1+a12*f2+u1
x2<-a21*f1+a22+f2+u2
x2<-a21*f1+a22*f2+u2
x3<-a31*f1+a32*f2+u3
x4<-a41*f1+a42*f2+u4
x5<-a51*f1+a52*f2+u5
データ行列<-cbind(x1,x2,x3,x4,x5)

factanal(データ行列,factors = 2)
Uniquenesses:
  x1    x2    x3    x4    x5 
0.678 0.478 0.497 0.667 0.698 

Loadings:
  Factor1 Factor2
x1 0.531   0.202  
x2 0.686   0.227  
x3 0.221   0.674  
x4 0.220   0.534  
x5 0.394   0.384  
# 因子負荷aに設定した0.6, 0.2, 0.4にほぼ同じ

#行列を使って作成するやり方
サンプルサイズ<-1000
因子負荷行列<-matrix(c(0.6,0.6,0.2,0.2,0.4,0.2,0.2,0.6,0.6,0.4),nrow = 5)
因子負荷行列
[,1] [,2]
[1,]  0.6  0.2
[2,]  0.6  0.2
[3,]  0.2  0.6
[4,]  0.2  0.6
[5,]  0.4  0.4
独自性<-diag(sqrt(c(0.6,0.6,0.6,0.6,0.68))) #diag;対角行列をつくる
独自性
[,1]      [,2]      [,3]      [,4]      [,5]
[1,] 0.7745967 0.0000000 0.0000000 0.0000000 0.0000000
[2,] 0.0000000 0.7745967 0.0000000 0.0000000 0.0000000
[3,] 0.0000000 0.0000000 0.7745967 0.0000000 0.0000000
[4,] 0.0000000 0.0000000 0.0000000 0.7745967 0.0000000
[5,] 0.0000000 0.0000000 0.0000000 0.0000000 0.8246211

因子得点<-matrix(rnorm(2*サンプルサイズ),nrow = 2)
独自因子<-matrix(rnorm(5*サンプルサイズ),nrow = 5)
観測値<-round(t(因子負荷行列%*%因子得点+独自性%*%独自因子))
factanal(観測値,factors = 2)
Uniquenesses:
  [1] 0.630 0.604 0.661 0.612 0.657

Loadings:
  Factor1 Factor2
[1,] 0.171   0.584  
[2,] 0.217   0.591  
[3,] 0.560   0.158  
[4,] 0.591   0.196  
[5,] 0.438   0.390  


#第20章
#モンテカルロシミュレーション
t値<-numeric(length = 10000)
有意回数<-0
for(i in 1:10000) {
第1群<-rnorm(n=10,mean=0,sd=1)
第2群<-rnorm(n=10,mean=0.5,sd=1)
検定結果<-t.test(第1群,第2群,var.equal = TRUE)
t値[i]<-検定結果[[1]]
有意回数<-有意回数+ifelse(検定結果[[3]]<0.05,1,0) #P値の棄却域が0.05以下なら有意回数に1を加算していく
}
有意回数/10000
#0.188などと、あきらかに平均値が違うサンプル同士なのに有意差はせいぜい19%程度の検定力という結果に。これはnの値を増やせば1.0に近づく
#どのようにnの最小値を決めるか？
power.t.test(n=NULL,delta=0.5,sd=1,sig.level = 0.05,power=0.8,strict = TRUE) #power1（検定力）0.8であるようなnを知りたい場合
n = 63.76561
delta = 0.5
sd = 1
sig.level = 0.05
power = 0.8
alternative = two.sided
#少なくとも64個のn数でイケる、とわかる。

#pwrパッケージ
library(pwr)
#一元配置分散分析、カイ二乗検定、正規分布平均値の検定、無相関検定、t検定などの最低標本データ数を自動出力してくれる
#上記、モンテカルロシミュレーションの場合
cohen.ES(test='t',size='medium') #で、t検定の場合の「中くらいの効果」の場合の“効果の大きさ”を提案してもらう
test = t
size = medium
effect.size = 0.5
#提案された効果のサイズは0.5
pwr.t.test(n=NULL,d=0.5,sig.level = 0.05,power=0.8)
Two-sample t test power calculation 

n = 63.76561
d = 0.5
sig.level = 0.05
power = 0.8
alternative = two.sided

NOTE: n is number in *each* group
#ということで、nは最低64データ欲しいところ。とわかる。

#カイ二乗検定
cohen.ES(test = 'chisq',size='medium')
test = chisq
size = medium
effect.size = 0.3
pwr.chisq.test(w=0.3,df=1,power=0.8) # wが効果の大きさ,dfは自由度=(行数-1)×(列数-1)
Chi squared power calculation 

w = 0.3
N = 87.20954
df = 1
sig.level = 0.05
power = 0.8

#クロス集計表の総度数（P129）が最低88欲しいところ。


#一元配置分散分析
cohen.ES(test = 'anov',size='medium')
test = anov
size = medium
effect.size = 0.25
pwr.anova.test(k=4,f=0.25,power = 0.8) # Kは群の数、fが効果の大きさ。
k = 4
n = 44.59927
f = 0.25
sig.level = 0.05
power = 0.8
#少なくとも1群あたり45データ欲しいところ。